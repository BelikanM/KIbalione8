"""
SystÃ¨me Vocal pour Kibali - Voice Agent
Transcription (Whisper) + SynthÃ¨se vocale (Coqui TTS)
"""

import os
import numpy as np
import soundfile as sf
import sounddevice as sd
from typing import Optional, Tuple
import tempfile
import time

class VoiceAgent:
    """Agent vocal pour Kibali Analyst avec Whisper + Coqui TTS"""
    
    def __init__(self, 
                 whisper_model: str = "base",
                 tts_model: str = "tts_models/fr/mai/tacotron2-DDC",
                 cache_dir: str = "/root/.cache/voice_models"):
        """
        Args:
            whisper_model: 'tiny' (~1GB), 'base' (~1.5GB), 'small' (~2GB)
            tts_model: ModÃ¨le Coqui TTS franÃ§ais
            cache_dir: Dossier de cache des modÃ¨les
        """
        self.whisper_model_name = whisper_model
        self.tts_model_name = tts_model
        self.cache_dir = cache_dir
        
        self.whisper = None
        self.tts = None
        self.is_ready = False
        
        # CrÃ©er le dossier de cache
        os.makedirs(cache_dir, exist_ok=True)
    
    def load_models(self, load_whisper: bool = True, load_tts: bool = True):
        """Charge les modÃ¨les vocaux"""
        try:
            # 1. Whisper pour transcription
            if load_whisper:
                print("ðŸŽ¤ Chargement de Whisper (transcription)...")
                import whisper
                
                self.whisper = whisper.load_model(
                    self.whisper_model_name,
                    download_root=os.path.join(self.cache_dir, "whisper")
                )
                print(f"âœ… Whisper '{self.whisper_model_name}' chargÃ©")
            
            # 2. Coqui TTS pour synthÃ¨se vocale
            if load_tts:
                print("ðŸ”Š Chargement de Coqui TTS (synthÃ¨se vocale)...")
                import torch
                from TTS.api import TTS
                
                # Correction pour PyTorch 2.6+ : permettre le chargement des modÃ¨les TTS
                original_load = torch.load
                def patched_load(*args, **kwargs):
                    # Forcer weights_only=False pour la compatibilitÃ© TTS
                    kwargs['weights_only'] = False
                    return original_load(*args, **kwargs)
                
                # Patch temporairement torch.load
                torch.load = patched_load
                
                try:
                    # ModÃ¨le franÃ§ais haute qualitÃ©
                    self.tts = TTS(
                        model_name=self.tts_model_name,
                        progress_bar=True,
                        gpu=False  # CPU pour compatibilitÃ©
                    )
                    print(f"âœ… TTS '{self.tts_model_name}' chargÃ©")
                finally:
                    # Restaurer torch.load original
                    torch.load = original_load
            
            self.is_ready = True
            return True
            
        except Exception as e:
            print(f"âŒ Erreur chargement modÃ¨les: {e}")
            return False
    
    def transcribe_audio(self, 
                        audio_path: str = None,
                        audio_array: np.ndarray = None,
                        language: str = "fr") -> Optional[str]:
        """
        Transcrit un audio en texte avec Whisper
        
        Args:
            audio_path: Chemin vers fichier audio
            audio_array: Array numpy (alternative)
            language: Code langue ('fr', 'en', etc.)
        
        Returns:
            str: Texte transcrit ou None si erreur
        """
        if self.whisper is None:
            print("âŒ Whisper non chargÃ©")
            return None
        
        try:
            # Si audio_array fourni, sauvegarder temporairement
            if audio_array is not None:
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                    sf.write(f.name, audio_array, 16000)
                    audio_path = f.name
            
            if not audio_path or not os.path.exists(audio_path):
                print("âŒ Fichier audio introuvable")
                return None
            
            # Transcription avec Whisper
            result = self.whisper.transcribe(
                audio_path,
                language=language,
                fp16=False,  # CPU compatible
                verbose=False
            )
            
            text = result["text"].strip()
            
            # Nettoyer le fichier temporaire
            if audio_array is not None:
                try:
                    os.unlink(audio_path)
                except:
                    pass
            
            return text
            
        except Exception as e:
            print(f"âŒ Erreur transcription: {e}")
            return None
    
    def record_audio(self, duration: int = 5, sample_rate: int = 16000) -> np.ndarray:
        """
        Enregistre de l'audio depuis le microphone
        
        Args:
            duration: DurÃ©e en secondes
            sample_rate: FrÃ©quence d'Ã©chantillonnage
        
        Returns:
            np.ndarray: Audio enregistrÃ©
        """
        print(f"ðŸŽ¤ Enregistrement ({duration}s)...")
        
        try:
            audio = sd.rec(
                int(duration * sample_rate),
                samplerate=sample_rate,
                channels=1,
                dtype='float32'
            )
            sd.wait()  # Attendre la fin
            
            print("âœ… Enregistrement terminÃ©")
            return audio.flatten()
            
        except Exception as e:
            print(f"âŒ Erreur enregistrement: {e}")
            return np.array([])
    
    def synthesize_speech(self, 
                         text: str,
                         output_path: str = None,
                         play: bool = False) -> Optional[str]:
        """
        SynthÃ©tise de la parole Ã  partir de texte
        
        Args:
            text: Texte Ã  synthÃ©tiser
            output_path: Chemin de sortie (optionnel)
            play: Jouer directement l'audio
        
        Returns:
            str: Chemin du fichier audio gÃ©nÃ©rÃ©
        """
        if self.tts is None:
            print("âŒ TTS non chargÃ©")
            return None
        
        try:
            # GÃ©nÃ©rer un nom de fichier si non fourni
            if output_path is None:
                timestamp = int(time.time())
                output_path = f"/tmp/kibali_voice_{timestamp}.wav"
            
            # SynthÃ¨se avec Coqui TTS
            print("ðŸ”Š GÃ©nÃ©ration de la parole...")
            self.tts.tts_to_file(
                text=text,
                file_path=output_path
            )
            
            print(f"âœ… Audio gÃ©nÃ©rÃ©: {output_path}")
            
            # Jouer l'audio si demandÃ©
            if play:
                self.play_audio(output_path)
            
            return output_path
            
        except Exception as e:
            print(f"âŒ Erreur synthÃ¨se: {e}")
            return None
    
    def play_audio(self, audio_path: str):
        """Joue un fichier audio"""
        try:
            data, sample_rate = sf.read(audio_path)
            sd.play(data, sample_rate)
            sd.wait()
            print("âœ… Lecture terminÃ©e")
        except Exception as e:
            print(f"âŒ Erreur lecture: {e}")
    
    def voice_conversation(self, 
                          callback_function,
                          record_duration: int = 5,
                          auto_play: bool = True) -> Tuple[str, str, str]:
        """
        Conversation vocale complÃ¨te: enregistrement â†’ transcription â†’ rÃ©ponse â†’ synthÃ¨se
        
        Args:
            callback_function: Fonction qui prend le texte transcrit et retourne la rÃ©ponse
            record_duration: DurÃ©e d'enregistrement
            auto_play: Jouer automatiquement la rÃ©ponse
        
        Returns:
            (transcription, rÃ©ponse_texte, audio_path)
        """
        # 1. Enregistrer
        print("\nðŸŽ¤ === CONVERSATION VOCALE ===")
        audio = self.record_audio(duration=record_duration)
        
        if len(audio) == 0:
            return "", "", ""
        
        # 2. Transcrire
        print("\nðŸ“ Transcription...")
        transcription = self.transcribe_audio(audio_array=audio)
        
        if not transcription:
            return "", "", ""
        
        print(f"âœ… Vous: {transcription}")
        
        # 3. Obtenir la rÃ©ponse (callback)
        print("\nðŸ¤– Kibali rÃ©flÃ©chit...")
        response_text = callback_function(transcription)
        
        if not response_text:
            return transcription, "", ""
        
        print(f"âœ… Kibali: {response_text[:100]}...")
        
        # 4. SynthÃ©tiser la rÃ©ponse
        print("\nðŸ”Š SynthÃ¨se vocale...")
        audio_path = self.synthesize_speech(
            response_text,
            play=auto_play
        )
        
        print("\nâœ… === CONVERSATION TERMINÃ‰E ===\n")
        
        return transcription, response_text, audio_path or ""


class StreamingVoiceAgent(VoiceAgent):
    """Version amÃ©liorÃ©e avec streaming audio pour fluiditÃ©"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.is_recording = False
        self.recorded_chunks = []
    
    def start_recording_stream(self, callback=None):
        """DÃ©marre l'enregistrement en streaming"""
        self.is_recording = True
        self.recorded_chunks = []
        
        def audio_callback(indata, frames, time_info, status):
            if status:
                print(f"âš ï¸ {status}")
            if self.is_recording:
                self.recorded_chunks.append(indata.copy())
                if callback:
                    callback(indata)
        
        self.stream = sd.InputStream(
            callback=audio_callback,
            channels=1,
            samplerate=16000,
            dtype='float32'
        )
        self.stream.start()
        print("ðŸŽ¤ Enregistrement streaming dÃ©marrÃ©")
    
    def stop_recording_stream(self) -> np.ndarray:
        """ArrÃªte l'enregistrement et retourne l'audio"""
        self.is_recording = False
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        if self.recorded_chunks:
            audio = np.concatenate(self.recorded_chunks, axis=0)
            print(f"âœ… Audio capturÃ©: {len(audio)} samples")
            return audio.flatten()
        
        return np.array([])
    
    def synthesize_streaming(self, text: str, chunk_size: int = 50):
        """
        SynthÃ¨se vocale par morceaux pour plus de fluiditÃ©
        (Simulation - TTS complet pour l'instant)
        """
        # Pour l'instant, utiliser la synthÃ¨se normale
        # TODO: ImplÃ©menter streaming rÃ©el si Coqui TTS le supporte
        return self.synthesize_speech(text, play=True)


def download_voice_models():
    """TÃ©lÃ©charge les modÃ¨les vocaux optimaux"""
    print("ðŸ“¦ TÃ©lÃ©chargement des modÃ¨les vocaux...")
    
    # 1. Whisper
    print("\n1ï¸âƒ£ Whisper (transcription)")
    print("   ModÃ¨le: base (~150MB)")
    import whisper
    whisper.load_model("base", download_root="/root/.cache/voice_models/whisper")
    print("   âœ… Whisper tÃ©lÃ©chargÃ©")
    
    # 2. Coqui TTS
    print("\n2ï¸âƒ£ Coqui TTS (synthÃ¨se vocale)")
    print("   ModÃ¨le: French Tacotron2 (~500MB)")
    from TTS.api import TTS
    
    # Lister les modÃ¨les disponibles
    tts = TTS(model_name="tts_models/fr/mai/tacotron2-DDC")
    print("   âœ… Coqui TTS tÃ©lÃ©chargÃ©")
    
    print("\nâœ… Tous les modÃ¨les vocaux sont prÃªts!")
    print("ðŸ“Š Taille totale: ~650MB")
    
    return True


if __name__ == '__main__':
    # Test du systÃ¨me vocal
    print("=== TEST VOICE AGENT ===\n")
    
    # Option 1: TÃ©lÃ©charger les modÃ¨les
    choice = input("TÃ©lÃ©charger les modÃ¨les? (o/N): ")
    if choice.lower() in ['o', 'oui', 'y', 'yes']:
        download_voice_models()
    
    # Option 2: Test rapide
    print("\n=== TEST TRANSCRIPTION ===")
    agent = VoiceAgent(whisper_model="base")
    
    if agent.load_models(load_whisper=True, load_tts=False):
        print("\nðŸŽ¤ Enregistrez un message de 5 secondes...")
        time.sleep(1)
        
        audio = agent.record_audio(duration=5)
        
        if len(audio) > 0:
            text = agent.transcribe_audio(audio_array=audio)
            print(f"\nâœ… Transcription: {text}")
    
    print("\n=== TEST SYNTHÃˆSE VOCALE ===")
    agent2 = VoiceAgent()
    
    if agent2.load_models(load_whisper=False, load_tts=True):
        text_to_speak = "Bonjour, je suis Kibali Analyst, votre assistant vocal intelligent."
        audio_file = agent2.synthesize_speech(text_to_speak, play=True)
        print(f"\nâœ… Audio gÃ©nÃ©rÃ©: {audio_file}")
