#!/usr/bin/env python3
"""
Script de t√©l√©chargement et v√©rification des mod√®les IA
Pour KIbalione8 - Syst√®me d'analyse ERT avanc√©
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple
import json

def print_section(title: str):
    """Affiche une section"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}\n")

def check_disk_space() -> Tuple[int, int]:
    """V√©rifie l'espace disque disponible"""
    import shutil
    stat = shutil.disk_usage(Path.home())
    free_gb = stat.free / (1024**3)
    total_gb = stat.total / (1024**3)
    return free_gb, total_gb

def download_embedding_models():
    """T√©l√©charge les mod√®les d'embedding"""
    print_section("1. Mod√®les d'Embedding")
    
    models = [
        "sentence-transformers/all-MiniLM-L6-v2",
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    ]
    
    try:
        from sentence_transformers import SentenceTransformer
        
        for model_name in models:
            print(f"üì• T√©l√©chargement: {model_name}...")
            model = SentenceTransformer(model_name)
            print(f"‚úÖ {model_name} t√©l√©charg√©")
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False
    
    return True

def download_whisper_models():
    """T√©l√©charge les mod√®les Whisper"""
    print_section("2. Mod√®les Whisper (Speech-to-Text)")
    
    models = ["tiny", "base", "small"]  # Mod√®les l√©gers
    
    try:
        import whisper
        
        for model_name in models:
            print(f"üì• T√©l√©chargement Whisper '{model_name}'...")
            model = whisper.load_model(model_name)
            print(f"‚úÖ Whisper '{model_name}' t√©l√©charg√©")
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        print("‚ö†Ô∏è  Installation de Whisper requise: pip install openai-whisper")
        return False
    
    return True

def download_tts_models():
    """T√©l√©charge les mod√®les TTS"""
    print_section("3. Mod√®les TTS (Text-to-Speech)")
    
    try:
        from TTS.api import TTS
        
        # Mod√®le fran√ßais l√©ger
        model_name = "tts_models/fr/mai/tacotron2-DDC"
        
        print(f"üì• T√©l√©chargement TTS: {model_name}...")
        tts = TTS(model_name)
        print(f"‚úÖ TTS '{model_name}' t√©l√©charg√©")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        print("‚ö†Ô∏è  Installation de TTS requise: pip install TTS")
        return False
    
    return True

def verify_llm_access():
    """V√©rifie l'acc√®s aux mod√®les LLM via HuggingFace"""
    print_section("4. Mod√®les LLM (Large Language Models)")
    
    from dotenv import load_dotenv
    load_dotenv()
    
    hf_token = os.getenv("HF_TOKEN")
    
    if not hf_token:
        print("‚ùå HF_TOKEN non configur√© dans .env")
        print("   Obtenez un token: https://huggingface.co/settings/tokens")
        return False
    
    print(f"‚úÖ Token HuggingFace configur√©: {hf_token[:10]}...")
    
    # Test d'acc√®s
    try:
        from huggingface_hub import HfApi
        api = HfApi(token=hf_token)
        
        # V√©rifier l'acc√®s √† un mod√®le public
        test_model = "Qwen/Qwen2.5-7B-Instruct"
        print(f"üîç V√©rification acc√®s √† {test_model}...")
        
        model_info = api.model_info(test_model)
        print(f"‚úÖ Acc√®s confirm√©: {test_model}")
        print(f"   Taille: ~{model_info.safetensors['total']/1e9:.1f}GB")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Impossible de v√©rifier l'acc√®s: {e}")
        print("   Le mod√®le sera t√©l√©charg√© au premier usage")
    
    return True

def verify_tavily_access():
    """V√©rifie l'acc√®s √† Tavily API"""
    print_section("5. Tavily API (Recherche Web)")
    
    from dotenv import load_dotenv
    load_dotenv()
    
    tavily_key = os.getenv("TAVILY_API_KEY")
    
    if not tavily_key:
        print("‚ùå TAVILY_API_KEY non configur√© dans .env")
        print("   Obtenez une cl√©: https://tavily.com")
        return False
    
    print(f"‚úÖ Cl√© Tavily configur√©e: {tavily_key[:10]}...")
    
    # Test de connexion
    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=tavily_key)
        
        print("üîç Test de recherche...")
        result = client.search("test", max_results=1)
        print("‚úÖ Connexion Tavily fonctionnelle")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur de connexion: {e}")
        print("   V√©rifiez votre cl√© API")
        return False
    
    return True

def check_dependencies():
    """V√©rifie les d√©pendances critiques"""
    print_section("6. V√©rification des D√©pendances")
    
    critical_packages = {
        "torch": "PyTorch",
        "transformers": "Transformers",
        "langchain": "LangChain",
        "streamlit": "Streamlit",
        "numpy": "NumPy",
        "pandas": "Pandas",
        "matplotlib": "Matplotlib",
        "faiss": "FAISS (CPU)",
        "sentence_transformers": "Sentence Transformers",
    }
    
    optional_packages = {
        "whisper": "Whisper (Voice)",
        "TTS": "Coqui TTS (Voice)",
        "pygimli": "PyGIMLi (Geophysics)",
        "pyres": "PyRes (ERT)",
    }
    
    print("üì¶ Packages critiques:")
    critical_ok = True
    for package, name in critical_packages.items():
        try:
            __import__(package)
            print(f"  ‚úÖ {name}")
        except ImportError:
            print(f"  ‚ùå {name} - MANQUANT")
            critical_ok = False
    
    print("\nüì¶ Packages optionnels:")
    for package, name in optional_packages.items():
        try:
            __import__(package)
            print(f"  ‚úÖ {name}")
        except ImportError:
            print(f"  ‚ö†Ô∏è  {name} - Non install√© (optionnel)")
    
    return critical_ok

def create_model_registry():
    """Cr√©e un registre des mod√®les disponibles"""
    print_section("7. Cr√©ation du Registre des Mod√®les")
    
    registry = {
        "embeddings": {
            "all-MiniLM-L6-v2": {
                "model_id": "sentence-transformers/all-MiniLM-L6-v2",
                "size_mb": 90,
                "languages": ["en"],
                "use_case": "embeddings_fast"
            },
            "paraphrase-multilingual": {
                "model_id": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
                "size_mb": 420,
                "languages": ["multilingual"],
                "use_case": "embeddings_multilingual"
            }
        },
        "llm": {
            "qwen-7b": {
                "model_id": "Qwen/Qwen2.5-7B-Instruct",
                "size_gb": 4.2,
                "context_length": 8192,
                "use_case": "general_purpose"
            },
            "gemma-2b": {
                "model_id": "google/gemma-2-2b-it",
                "size_gb": 2.5,
                "context_length": 8192,
                "use_case": "lightweight"
            },
            "deepseek-v3": {
                "model_id": "deepseek-ai/DeepSeek-V3-0324",
                "size_gb": 14.0,
                "context_length": 32768,
                "use_case": "advanced_reasoning"
            }
        },
        "voice": {
            "whisper-base": {
                "model_id": "openai/whisper-base",
                "size_mb": 150,
                "use_case": "speech_to_text"
            },
            "tts-fr": {
                "model_id": "tts_models/fr/mai/tacotron2-DDC",
                "size_mb": 250,
                "use_case": "text_to_speech_french"
            }
        }
    }
    
    registry_path = Path("local_models_paths.json")
    with open(registry_path, 'w', encoding='utf-8') as f:
        json.dump(registry, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Registre cr√©√©: {registry_path}")
    print(f"   - {len(registry['embeddings'])} mod√®les d'embedding")
    print(f"   - {len(registry['llm'])} mod√®les LLM")
    print(f"   - {len(registry['voice'])} mod√®les vocaux")
    
    return True

def display_summary(results: Dict[str, bool]):
    """Affiche un r√©sum√© de l'installation"""
    print_section("R√©sum√© de l'Installation")
    
    total = len(results)
    success = sum(results.values())
    
    print(f"üìä Taux de succ√®s: {success}/{total} ({success/total*100:.0f}%)")
    print("")
    
    for step, status in results.items():
        icon = "‚úÖ" if status else "‚ùå"
        print(f"  {icon} {step}")
    
    print("")
    
    if success == total:
        print("üéâ Installation compl√®te r√©ussie!")
        print("")
        print("üìã Prochaines √©tapes:")
        print("  1. Configurez vos tokens API dans .env")
        print("  2. Lancez l'application: streamlit run kibalione8.py")
    else:
        print("‚ö†Ô∏è  Installation partielle. V√©rifiez les erreurs ci-dessus.")
        print("")
        print("üí° Conseils:")
        print("  - Installez les packages manquants: pip install <package>")
        print("  - V√©rifiez votre connexion internet")
        print("  - Configurez correctement le fichier .env")

def main():
    """Fonction principale"""
    print("üöÄ KIbalione8 - T√©l√©chargement et V√©rification des Mod√®les")
    
    # V√©rifier l'espace disque
    free_gb, total_gb = check_disk_space()
    print(f"üíæ Espace disque: {free_gb:.1f}GB libres / {total_gb:.1f}GB total")
    
    if free_gb < 15:
        print("‚ö†Ô∏è  Espace disque faible! Au moins 15GB recommand√©s.")
        response = input("Continuer quand m√™me? (y/N): ")
        if response.lower() != 'y':
            print("‚ùå Installation annul√©e")
            return
    
    # Ex√©cuter les √©tapes
    results = {}
    
    results["D√©pendances"] = check_dependencies()
    
    if results["D√©pendances"]:
        results["Embeddings"] = download_embedding_models()
        results["Whisper"] = download_whisper_models()
        results["TTS"] = download_tts_models()
        results["LLM Access"] = verify_llm_access()
        results["Tavily API"] = verify_tavily_access()
        results["Registre"] = create_model_registry()
    else:
        print("‚ùå D√©pendances critiques manquantes. Installation arr√™t√©e.")
        print("üí° Ex√©cutez d'abord: pip install -r requirements_complete.txt")
        return
    
    # Afficher le r√©sum√©
    display_summary(results)

if __name__ == "__main__":
    main()
